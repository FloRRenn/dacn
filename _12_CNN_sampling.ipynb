{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, MaxPooling1D, Flatten, Dropout, Reshape, LayerNormalization, MultiHeadAttention, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score,  f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['destination_port',\n",
    "            'init_win_bytes_backward',\n",
    "            'init_win_bytes_forward',\n",
    "            'bwd_packets_s',\n",
    "            'fwd_iat_min',\n",
    "            'min_seg_size_forward',\n",
    "            'flow_iat_min',\n",
    "            'flow_duration',\n",
    "            'total_length_of_fwd_packets',\n",
    "            'total_backward_packets',\n",
    "            'bwd_iat_min',\n",
    "            'bwd_packet_length_std',\n",
    "            'fwd_iat_total',\n",
    "            'fwd_packet_length_mean',\n",
    "            'fwd_packet_length_max',\n",
    "            'flow_iat_std',\n",
    "            'fwd_packets_s',\n",
    "            'down_up_ratio',\n",
    "            'total_fwd_packets',\n",
    "            'bwd_packet_length_min',\n",
    "            'flow_bytes_s',\n",
    "            'bwd_header_length',\n",
    "            'packet_length_mean',\n",
    "            'total_length_of_bwd_packets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_datatype(df):\n",
    "    int8_vals = np.iinfo(np.int8)\n",
    "    int16_vals = np.iinfo(np.int16)\n",
    "    int32_vals = np.iinfo(np.int32)\n",
    "\n",
    "    float16_vals = np.finfo(np.float16)\n",
    "    float32_vals = np.finfo(np.float32)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        max_val = df[col].max()\n",
    "        min_val = df[col].min()\n",
    "\n",
    "        # print(f\"{col}: max {max_val} -- min {min_val}\")\n",
    "        \n",
    "        if df[col].dtype == np.int64:\n",
    "            if max_val <= int8_vals.max and min_val >= int8_vals.min:\n",
    "                df[col] = df[col].astype(np.int8)\n",
    "            elif max_val <= int16_vals.max and min_val >= int16_vals.min:\n",
    "                df[col] = df[col].astype(np.int16)\n",
    "            elif max_val <= int32_vals.max and min_val >= int32_vals.min:\n",
    "                df[col] = df[col].astype(np.int32)\n",
    "\n",
    "        elif df[col].dtype == np.float64:\n",
    "            if max_val <= float16_vals.max and min_val >= float16_vals.min:\n",
    "                df[col] = df[col].astype(np.float16)\n",
    "            elif max_val <= float32_vals.max and min_val >= float32_vals.min:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = change_datatype(pd.read_csv(\"./oversampling/NRAS_trainset.csv\"))\n",
    "df_test = change_datatype(pd.read_csv(\"./raw/raw_testset.csv\"))\n",
    "\n",
    "df_train = df_train[selected_features + ['label']]\n",
    "df_test = df_test[selected_features + ['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9539966, 25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(756690, 25)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = QuantileTransformer(\n",
    "       n_quantiles = 10000,\n",
    "       random_state = 6969,\n",
    "       output_distribution = \"uniform\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop('label', axis = 1)\n",
    "y_train = df_train['label']\n",
    "\n",
    "X_test = df_test.drop('label', axis = 1)\n",
    "y_test = df_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(756690, 24, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape = (X_train.shape[1], 1)),\n",
    "    Conv1D(512, 3, padding = \"same\", activation = \"relu\"),\n",
    "    LayerNormalization(),\n",
    "    \n",
    "    MaxPooling1D(pool_size = (2)),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Conv1D(128, 3, padding = \"same\", activation = \"relu\"),\n",
    "    MaxPooling1D(pool_size = (2)),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Conv1D(64, 4, padding = \"same\", activation = \"relu\"),\n",
    "    MaxPooling1D(pool_size = (2)),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation = \"relu\"),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(y_train.unique().shape[0], activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 24, 512)           2048      \n",
      "                                                                 \n",
      " layer_normalization (Layer  (None, 24, 512)           1024      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 12, 512)           0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 512)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 12, 128)           196736    \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 6, 128)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 6, 128)            0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 6, 64)             32832     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 3, 64)             0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 3, 64)             0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 192)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               24704     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 258634 (1010.29 KB)\n",
      "Trainable params: 258634 (1010.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "        loss = SparseCategoricalCrossentropy(),\n",
    "        optimizer = Adam(learning_rate = 0.001),\n",
    "        metrics = ['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"./checkpoint/model_weights_oversampling.hdf5\", \n",
    "                             monitor = 'val_loss', verbose = 1, \n",
    "                             save_best_only = True, mode = 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 5, \n",
    "                              min_lr = 1e-5, cooldown = 1, mode = \"min\", verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18633/18633 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.9554\n",
      "Epoch 1: val_loss improved from inf to 0.05108, saving model to ./checkpoint\\model_weights_oversampling.hdf5\n",
      "18633/18633 [==============================] - 8894s 477ms/step - loss: 0.1035 - accuracy: 0.9554 - val_loss: 0.0511 - val_accuracy: 0.9791 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dataset\\env\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "18633/18633 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.9659\n",
      "Epoch 2: val_loss improved from 0.05108 to 0.04729, saving model to ./checkpoint\\model_weights_oversampling.hdf5\n",
      "18633/18633 [==============================] - 8505s 456ms/step - loss: 0.0753 - accuracy: 0.9659 - val_loss: 0.0473 - val_accuracy: 0.9841 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "18633/18633 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.9709\n",
      "Epoch 3: val_loss improved from 0.04729 to 0.03976, saving model to ./checkpoint\\model_weights_oversampling.hdf5\n",
      "18633/18633 [==============================] - 8159s 438ms/step - loss: 0.0645 - accuracy: 0.9709 - val_loss: 0.0398 - val_accuracy: 0.9874 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "18633/18633 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.9738\n",
      "Epoch 4: val_loss improved from 0.03976 to 0.03863, saving model to ./checkpoint\\model_weights_oversampling.hdf5\n",
      "18633/18633 [==============================] - 10916s 586ms/step - loss: 0.0570 - accuracy: 0.9738 - val_loss: 0.0386 - val_accuracy: 0.9860 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "18633/18633 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9764\n",
      "Epoch 5: val_loss improved from 0.03863 to 0.03485, saving model to ./checkpoint\\model_weights_oversampling.hdf5\n",
      "18633/18633 [==============================] - 9082s 487ms/step - loss: 0.0525 - accuracy: 0.9764 - val_loss: 0.0349 - val_accuracy: 0.9904 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "18633/18633 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9803\n",
      "Epoch 6: val_loss improved from 0.03485 to 0.02841, saving model to ./checkpoint\\model_weights_oversampling.hdf5\n",
      "18633/18633 [==============================] - 7814s 419ms/step - loss: 0.0474 - accuracy: 0.9803 - val_loss: 0.0284 - val_accuracy: 0.9938 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "18633/18633 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.9838\n",
      "Epoch 7: val_loss improved from 0.02841 to 0.02837, saving model to ./checkpoint\\model_weights_oversampling.hdf5\n",
      "18633/18633 [==============================] - 7830s 420ms/step - loss: 0.0422 - accuracy: 0.9838 - val_loss: 0.0284 - val_accuracy: 0.9920 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "18633/18633 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.9853\n",
      "Epoch 8: val_loss did not improve from 0.02837\n",
      "18633/18633 [==============================] - 7888s 423ms/step - loss: 0.0394 - accuracy: 0.9853 - val_loss: 0.0294 - val_accuracy: 0.9912 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "18633/18633 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9865\n",
      "Epoch 9: val_loss did not improve from 0.02837\n",
      "18633/18633 [==============================] - 4781s 257ms/step - loss: 0.0369 - accuracy: 0.9865 - val_loss: 0.0343 - val_accuracy: 0.9883 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "18633/18633 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9874\n",
      "Epoch 10: val_loss improved from 0.02837 to 0.02803, saving model to ./checkpoint\\model_weights_oversampling.hdf5\n",
      "18633/18633 [==============================] - 4752s 255ms/step - loss: 0.0348 - accuracy: 0.9874 - val_loss: 0.0280 - val_accuracy: 0.9918 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "18633/18633 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9880\n",
      "Epoch 11: val_loss improved from 0.02803 to 0.02562, saving model to ./checkpoint\\model_weights_oversampling.hdf5\n",
      "18633/18633 [==============================] - 4451s 239ms/step - loss: 0.0334 - accuracy: 0.9880 - val_loss: 0.0256 - val_accuracy: 0.9925 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "18633/18633 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9885\n",
      "Epoch 12: val_loss did not improve from 0.02562\n",
      "18633/18633 [==============================] - 4316s 232ms/step - loss: 0.0322 - accuracy: 0.9885 - val_loss: 0.0342 - val_accuracy: 0.9860 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "18633/18633 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9889\n",
      "Epoch 13: val_loss did not improve from 0.02562\n",
      "18633/18633 [==============================] - 4174s 224ms/step - loss: 0.0313 - accuracy: 0.9889 - val_loss: 0.0283 - val_accuracy: 0.9917 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "18633/18633 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.9893\n",
      "Epoch 14: val_loss improved from 0.02562 to 0.02257, saving model to ./checkpoint\\model_weights_oversampling.hdf5\n",
      "18633/18633 [==============================] - 4650s 250ms/step - loss: 0.0305 - accuracy: 0.9893 - val_loss: 0.0226 - val_accuracy: 0.9933 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "18633/18633 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9896\n",
      "Epoch 15: val_loss did not improve from 0.02257\n",
      "18633/18633 [==============================] - 4437s 238ms/step - loss: 0.0298 - accuracy: 0.9896 - val_loss: 0.0227 - val_accuracy: 0.9937 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train,\n",
    "                    validation_data = (X_test, y_test), \n",
    "                    epochs = 15, batch_size = 512, \n",
    "                    callbacks = [checkpoint, reduce_lr])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
