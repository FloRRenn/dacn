{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, MaxPooling1D, Flatten, Dropout, Reshape, LayerNormalization, MultiHeadAttention, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score,  f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['destination_port',\n",
    "            'init_win_bytes_backward',\n",
    "            'init_win_bytes_forward',\n",
    "            'bwd_packets_s',\n",
    "            'fwd_iat_min',\n",
    "            'min_seg_size_forward',\n",
    "            'flow_iat_min',\n",
    "            'flow_duration',\n",
    "            'total_length_of_fwd_packets',\n",
    "            'total_backward_packets',\n",
    "            'bwd_iat_min',\n",
    "            'bwd_packet_length_std',\n",
    "            'fwd_iat_total',\n",
    "            'fwd_packet_length_mean',\n",
    "            'fwd_packet_length_max',\n",
    "            'flow_iat_std',\n",
    "            'fwd_packets_s',\n",
    "            'down_up_ratio',\n",
    "            'total_fwd_packets',\n",
    "            'bwd_packet_length_min',\n",
    "            'flow_bytes_s',\n",
    "            'bwd_header_length',\n",
    "            'packet_length_mean',\n",
    "            'total_length_of_bwd_packets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_datatype(df):\n",
    "    int8_vals = np.iinfo(np.int8)\n",
    "    int16_vals = np.iinfo(np.int16)\n",
    "    int32_vals = np.iinfo(np.int32)\n",
    "\n",
    "    float16_vals = np.finfo(np.float16)\n",
    "    float32_vals = np.finfo(np.float32)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        max_val = df[col].max()\n",
    "        min_val = df[col].min()\n",
    "\n",
    "        # print(f\"{col}: max {max_val} -- min {min_val}\")\n",
    "        \n",
    "        if df[col].dtype == np.int64:\n",
    "            if max_val <= int8_vals.max and min_val >= int8_vals.min:\n",
    "                df[col] = df[col].astype(np.int8)\n",
    "            elif max_val <= int16_vals.max and min_val >= int16_vals.min:\n",
    "                df[col] = df[col].astype(np.int16)\n",
    "            elif max_val <= int32_vals.max and min_val >= int32_vals.min:\n",
    "                df[col] = df[col].astype(np.int32)\n",
    "\n",
    "        elif df[col].dtype == np.float64:\n",
    "            if max_val <= float16_vals.max and min_val >= float16_vals.min:\n",
    "                df[col] = df[col].astype(np.float16)\n",
    "            elif max_val <= float32_vals.max and min_val >= float32_vals.min:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = change_datatype(pd.read_csv(\"./raw/raw_cutoff_trainset.csv\"))\n",
    "df_test = change_datatype(pd.read_csv(\"./raw/raw_testset.csv\"))\n",
    "\n",
    "df_train = df_train[selected_features + ['label']]\n",
    "df_test = df_test[selected_features + ['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1251919, 25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(756690, 25)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop('label', axis = 1)\n",
    "y_train = df_train['label']\n",
    "\n",
    "X_test = df_test.drop('label', axis = 1)\n",
    "y_test = df_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = QuantileTransformer(\n",
    "       n_quantiles = 10000,\n",
    "       random_state = 6969,\n",
    "       output_distribution = \"uniform\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1251919, 24)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1251919, 24, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(756690, 24, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.unique().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape = (X_train.shape[1], 1)),\n",
    "    Conv1D(512, 3, padding = \"same\", activation = \"relu\"),\n",
    "    LayerNormalization(),\n",
    "    \n",
    "    MaxPooling1D(pool_size = (2)),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Conv1D(128, 3, padding = \"same\", activation = \"relu\"),\n",
    "    MaxPooling1D(pool_size = (2)),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Conv1D(64, 4, padding = \"same\", activation = \"relu\"),\n",
    "    MaxPooling1D(pool_size = (2)),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation = \"relu\"),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(y_train.unique().shape[0], activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 24, 512)           2048      \n",
      "                                                                 \n",
      " layer_normalization_1 (Lay  (None, 24, 512)           1024      \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 12, 512)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 12, 512)           0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 12, 128)           196736    \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 6, 128)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 6, 128)            0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 6, 64)             32832     \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPoolin  (None, 3, 64)             0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 3, 64)             0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 192)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               24704     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 258634 (1010.29 KB)\n",
      "Trainable params: 258634 (1010.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "        loss = SparseCategoricalCrossentropy(),\n",
    "        optimizer = Adam(learning_rate = 0.001),\n",
    "        metrics = ['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"./checkpoint/model_weights.h5\", \n",
    "                             monitor = 'val_loss', verbose = 1, \n",
    "                             save_best_only = True, mode = 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2,npatience = 5, \n",
    "                              min_lr = 1e-5, cooldown = 1, mode = \"min\", verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "2445/2446 [============================>.] - ETA: 0s - loss: 0.0631 - accuracy: 0.9826\n",
      "Epoch 1: val_loss improved from inf to 0.01966, saving model to ./checkpoint\\model_weights.h5\n",
      "2446/2446 [==============================] - 655s 268ms/step - loss: 0.0631 - accuracy: 0.9826 - val_loss: 0.0197 - val_accuracy: 0.9950 - lr: 0.0010\n",
      "Epoch 2/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dataset\\env\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2445/2446 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9908\n",
      "Epoch 2: val_loss improved from 0.01966 to 0.01625, saving model to ./checkpoint\\model_weights.h5\n",
      "2446/2446 [==============================] - 648s 265ms/step - loss: 0.0338 - accuracy: 0.9908 - val_loss: 0.0162 - val_accuracy: 0.9963 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "2445/2446 [============================>.] - ETA: 0s - loss: 0.0289 - accuracy: 0.9922\n",
      "Epoch 3: val_loss improved from 0.01625 to 0.01444, saving model to ./checkpoint\\model_weights.h5\n",
      "2446/2446 [==============================] - 646s 264ms/step - loss: 0.0289 - accuracy: 0.9922 - val_loss: 0.0144 - val_accuracy: 0.9968 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9929\n",
      "Epoch 4: val_loss improved from 0.01444 to 0.01353, saving model to ./checkpoint\\model_weights.h5\n",
      "2446/2446 [==============================] - 800s 327ms/step - loss: 0.0259 - accuracy: 0.9929 - val_loss: 0.0135 - val_accuracy: 0.9963 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "2445/2446 [============================>.] - ETA: 0s - loss: 0.0239 - accuracy: 0.9935\n",
      "Epoch 5: val_loss improved from 0.01353 to 0.01301, saving model to ./checkpoint\\model_weights.h5\n",
      "2446/2446 [==============================] - 799s 327ms/step - loss: 0.0239 - accuracy: 0.9935 - val_loss: 0.0130 - val_accuracy: 0.9970 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9939\n",
      "Epoch 6: val_loss improved from 0.01301 to 0.01288, saving model to ./checkpoint\\model_weights.h5\n",
      "2446/2446 [==============================] - 836s 342ms/step - loss: 0.0227 - accuracy: 0.9939 - val_loss: 0.0129 - val_accuracy: 0.9962 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9941\n",
      "Epoch 7: val_loss improved from 0.01288 to 0.00986, saving model to ./checkpoint\\model_weights.h5\n",
      "2446/2446 [==============================] - 1259s 515ms/step - loss: 0.0216 - accuracy: 0.9941 - val_loss: 0.0099 - val_accuracy: 0.9975 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9944\n",
      "Epoch 8: val_loss did not improve from 0.00986\n",
      "2446/2446 [==============================] - 1316s 538ms/step - loss: 0.0209 - accuracy: 0.9944 - val_loss: 0.0101 - val_accuracy: 0.9974 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9946\n",
      "Epoch 9: val_loss improved from 0.00986 to 0.00975, saving model to ./checkpoint\\model_weights.h5\n",
      "2446/2446 [==============================] - 1259s 515ms/step - loss: 0.0202 - accuracy: 0.9946 - val_loss: 0.0098 - val_accuracy: 0.9975 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9947\n",
      "Epoch 10: val_loss improved from 0.00975 to 0.00969, saving model to ./checkpoint\\model_weights.h5\n",
      "2446/2446 [==============================] - 1227s 502ms/step - loss: 0.0199 - accuracy: 0.9947 - val_loss: 0.0097 - val_accuracy: 0.9973 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9949\n",
      "Epoch 11: val_loss improved from 0.00969 to 0.00902, saving model to ./checkpoint\\model_weights.h5\n",
      "2446/2446 [==============================] - 1267s 518ms/step - loss: 0.0193 - accuracy: 0.9949 - val_loss: 0.0090 - val_accuracy: 0.9975 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9950\n",
      "Epoch 12: val_loss improved from 0.00902 to 0.00891, saving model to ./checkpoint\\model_weights.h5\n",
      "2446/2446 [==============================] - 1289s 527ms/step - loss: 0.0188 - accuracy: 0.9950 - val_loss: 0.0089 - val_accuracy: 0.9974 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9950\n",
      "Epoch 13: val_loss improved from 0.00891 to 0.00885, saving model to ./checkpoint\\model_weights.h5\n",
      "2446/2446 [==============================] - 1221s 499ms/step - loss: 0.0185 - accuracy: 0.9950 - val_loss: 0.0088 - val_accuracy: 0.9975 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9951\n",
      "Epoch 14: val_loss did not improve from 0.00885\n",
      "2446/2446 [==============================] - 1324s 541ms/step - loss: 0.0183 - accuracy: 0.9951 - val_loss: 0.0089 - val_accuracy: 0.9976 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9952\n",
      "Epoch 15: val_loss did not improve from 0.00885\n",
      "2446/2446 [==============================] - 1264s 517ms/step - loss: 0.0178 - accuracy: 0.9952 - val_loss: 0.0091 - val_accuracy: 0.9975 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9952\n",
      "Epoch 16: val_loss did not improve from 0.00885\n",
      "2446/2446 [==============================] - 1152s 471ms/step - loss: 0.0176 - accuracy: 0.9952 - val_loss: 0.0094 - val_accuracy: 0.9976 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9954\n",
      "Epoch 17: val_loss improved from 0.00885 to 0.00842, saving model to ./checkpoint\\model_weights.h5\n",
      "2446/2446 [==============================] - 1173s 480ms/step - loss: 0.0174 - accuracy: 0.9954 - val_loss: 0.0084 - val_accuracy: 0.9975 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9953\n",
      "Epoch 18: val_loss did not improve from 0.00842\n",
      "2446/2446 [==============================] - 1154s 472ms/step - loss: 0.0174 - accuracy: 0.9953 - val_loss: 0.0091 - val_accuracy: 0.9975 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9955\n",
      "Epoch 19: val_loss improved from 0.00842 to 0.00819, saving model to ./checkpoint\\model_weights.h5\n",
      "2446/2446 [==============================] - 1166s 477ms/step - loss: 0.0170 - accuracy: 0.9955 - val_loss: 0.0082 - val_accuracy: 0.9976 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9956\n",
      "Epoch 20: val_loss did not improve from 0.00819\n",
      "2446/2446 [==============================] - 1220s 499ms/step - loss: 0.0166 - accuracy: 0.9956 - val_loss: 0.0085 - val_accuracy: 0.9975 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9955\n",
      "Epoch 21: val_loss did not improve from 0.00819\n",
      "2446/2446 [==============================] - 1160s 474ms/step - loss: 0.0164 - accuracy: 0.9955 - val_loss: 0.0093 - val_accuracy: 0.9976 - lr: 0.0010\n",
      "Epoch 22/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9956\n",
      "Epoch 22: val_loss did not improve from 0.00819\n",
      "2446/2446 [==============================] - 1164s 476ms/step - loss: 0.0163 - accuracy: 0.9956 - val_loss: 0.0087 - val_accuracy: 0.9976 - lr: 0.0010\n",
      "Epoch 23/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9957\n",
      "Epoch 23: val_loss did not improve from 0.00819\n",
      "2446/2446 [==============================] - 1161s 475ms/step - loss: 0.0162 - accuracy: 0.9957 - val_loss: 0.0091 - val_accuracy: 0.9976 - lr: 0.0010\n",
      "Epoch 24/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9957\n",
      "Epoch 24: val_loss improved from 0.00819 to 0.00810, saving model to ./checkpoint\\model_weights.h5\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "2446/2446 [==============================] - 1147s 469ms/step - loss: 0.0160 - accuracy: 0.9957 - val_loss: 0.0081 - val_accuracy: 0.9977 - lr: 0.0010\n",
      "Epoch 25/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9963\n",
      "Epoch 25: val_loss improved from 0.00810 to 0.00792, saving model to ./checkpoint\\model_weights.h5\n",
      "2446/2446 [==============================] - 1141s 467ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.0079 - val_accuracy: 0.9977 - lr: 2.0000e-04\n",
      "Epoch 26/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9965\n",
      "Epoch 26: val_loss did not improve from 0.00792\n",
      "2446/2446 [==============================] - 1142s 467ms/step - loss: 0.0126 - accuracy: 0.9965 - val_loss: 0.0083 - val_accuracy: 0.9978 - lr: 2.0000e-04\n",
      "Epoch 27/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9965\n",
      "Epoch 27: val_loss improved from 0.00792 to 0.00781, saving model to ./checkpoint\\model_weights.h5\n",
      "2446/2446 [==============================] - 1147s 469ms/step - loss: 0.0123 - accuracy: 0.9965 - val_loss: 0.0078 - val_accuracy: 0.9978 - lr: 2.0000e-04\n",
      "Epoch 28/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9966\n",
      "Epoch 28: val_loss did not improve from 0.00781\n",
      "2446/2446 [==============================] - 1140s 466ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 0.0079 - val_accuracy: 0.9977 - lr: 2.0000e-04\n",
      "Epoch 29/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9966\n",
      "Epoch 29: val_loss did not improve from 0.00781\n",
      "2446/2446 [==============================] - 1488s 609ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.0078 - val_accuracy: 0.9978 - lr: 2.0000e-04\n",
      "Epoch 30/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9966\n",
      "Epoch 30: val_loss improved from 0.00781 to 0.00740, saving model to ./checkpoint\\model_weights.h5\n",
      "2446/2446 [==============================] - 3389s 1s/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.0074 - val_accuracy: 0.9978 - lr: 2.0000e-04\n",
      "Epoch 31/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9967\n",
      "Epoch 31: val_loss did not improve from 0.00740\n",
      "2446/2446 [==============================] - 1163s 476ms/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 0.0078 - val_accuracy: 0.9977 - lr: 2.0000e-04\n",
      "Epoch 32/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9967\n",
      "Epoch 32: val_loss did not improve from 0.00740\n",
      "2446/2446 [==============================] - 1179s 482ms/step - loss: 0.0118 - accuracy: 0.9967 - val_loss: 0.0076 - val_accuracy: 0.9979 - lr: 2.0000e-04\n",
      "Epoch 33/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9967\n",
      "Epoch 33: val_loss did not improve from 0.00740\n",
      "2446/2446 [==============================] - 1231s 503ms/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 0.0074 - val_accuracy: 0.9978 - lr: 2.0000e-04\n",
      "Epoch 34/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9967\n",
      "Epoch 34: val_loss did not improve from 0.00740\n",
      "2446/2446 [==============================] - 1173s 479ms/step - loss: 0.0115 - accuracy: 0.9967 - val_loss: 0.0076 - val_accuracy: 0.9979 - lr: 2.0000e-04\n",
      "Epoch 35/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9967\n",
      "Epoch 35: val_loss improved from 0.00740 to 0.00739, saving model to ./checkpoint\\model_weights.h5\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "2446/2446 [==============================] - 1237s 506ms/step - loss: 0.0114 - accuracy: 0.9967 - val_loss: 0.0074 - val_accuracy: 0.9978 - lr: 2.0000e-04\n",
      "Epoch 36/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9967\n",
      "Epoch 36: val_loss improved from 0.00739 to 0.00729, saving model to ./checkpoint\\model_weights.h5\n",
      "2446/2446 [==============================] - 1533s 627ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 0.0073 - val_accuracy: 0.9978 - lr: 4.0000e-05\n",
      "Epoch 37/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9968\n",
      "Epoch 37: val_loss did not improve from 0.00729\n",
      "2446/2446 [==============================] - 1574s 644ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.0073 - val_accuracy: 0.9978 - lr: 4.0000e-05\n",
      "Epoch 38/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9969\n",
      "Epoch 38: val_loss improved from 0.00729 to 0.00727, saving model to ./checkpoint\\model_weights.h5\n",
      "2446/2446 [==============================] - 1361s 556ms/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0073 - val_accuracy: 0.9979 - lr: 4.0000e-05\n",
      "Epoch 39/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9968\n",
      "Epoch 39: val_loss did not improve from 0.00727\n",
      "2446/2446 [==============================] - 1089s 445ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0073 - val_accuracy: 0.9979 - lr: 4.0000e-05\n",
      "Epoch 40/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9968\n",
      "Epoch 40: val_loss did not improve from 0.00727\n",
      "2446/2446 [==============================] - 1095s 448ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0073 - val_accuracy: 0.9979 - lr: 4.0000e-05\n",
      "Epoch 41/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9969\n",
      "Epoch 41: val_loss did not improve from 0.00727\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "2446/2446 [==============================] - 1094s 447ms/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0074 - val_accuracy: 0.9979 - lr: 4.0000e-05\n",
      "Epoch 42/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9969\n",
      "Epoch 42: val_loss did not improve from 0.00727\n",
      "2446/2446 [==============================] - 1085s 444ms/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0073 - val_accuracy: 0.9979 - lr: 1.0000e-05\n",
      "Epoch 43/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9968\n",
      "Epoch 43: val_loss did not improve from 0.00727\n",
      "2446/2446 [==============================] - 1090s 446ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.0073 - val_accuracy: 0.9979 - lr: 1.0000e-05\n",
      "Epoch 44/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9969\n",
      "Epoch 44: val_loss did not improve from 0.00727\n",
      "2446/2446 [==============================] - 1091s 446ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0073 - val_accuracy: 0.9979 - lr: 1.0000e-05\n",
      "Epoch 45/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9969\n",
      "Epoch 45: val_loss improved from 0.00727 to 0.00727, saving model to ./checkpoint\\model_weights.h5\n",
      "2446/2446 [==============================] - 1099s 450ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0073 - val_accuracy: 0.9979 - lr: 1.0000e-05\n",
      "Epoch 46/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9968\n",
      "Epoch 46: val_loss did not improve from 0.00727\n",
      "2446/2446 [==============================] - 1094s 447ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.0073 - val_accuracy: 0.9979 - lr: 1.0000e-05\n",
      "Epoch 47/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9969\n",
      "Epoch 47: val_loss did not improve from 0.00727\n",
      "2446/2446 [==============================] - 1099s 449ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0073 - val_accuracy: 0.9979 - lr: 1.0000e-05\n",
      "Epoch 48/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9969\n",
      "Epoch 48: val_loss did not improve from 0.00727\n",
      "2446/2446 [==============================] - 1101s 450ms/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0073 - val_accuracy: 0.9979 - lr: 1.0000e-05\n",
      "Epoch 49/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9969\n",
      "Epoch 49: val_loss did not improve from 0.00727\n",
      "2446/2446 [==============================] - 1086s 444ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0073 - val_accuracy: 0.9979 - lr: 1.0000e-05\n",
      "Epoch 50/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9969\n",
      "Epoch 50: val_loss did not improve from 0.00727\n",
      "2446/2446 [==============================] - 1093s 447ms/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0073 - val_accuracy: 0.9979 - lr: 1.0000e-05\n",
      "Epoch 51/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9969\n",
      "Epoch 51: val_loss improved from 0.00727 to 0.00723, saving model to ./checkpoint\\model_weights.h5\n",
      "2446/2446 [==============================] - 1094s 447ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0072 - val_accuracy: 0.9979 - lr: 1.0000e-05\n",
      "Epoch 52/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9969\n",
      "Epoch 52: val_loss did not improve from 0.00723\n",
      "2446/2446 [==============================] - 1100s 450ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0073 - val_accuracy: 0.9979 - lr: 1.0000e-05\n",
      "Epoch 53/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9969\n",
      "Epoch 53: val_loss did not improve from 0.00723\n",
      "2446/2446 [==============================] - 1093s 447ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0072 - val_accuracy: 0.9979 - lr: 1.0000e-05\n",
      "Epoch 54/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9969\n",
      "Epoch 54: val_loss did not improve from 0.00723\n",
      "2446/2446 [==============================] - 1098s 449ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0073 - val_accuracy: 0.9979 - lr: 1.0000e-05\n",
      "Epoch 55/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9969\n",
      "Epoch 55: val_loss did not improve from 0.00723\n",
      "2446/2446 [==============================] - 1088s 445ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0073 - val_accuracy: 0.9979 - lr: 1.0000e-05\n",
      "Epoch 56/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9968\n",
      "Epoch 56: val_loss did not improve from 0.00723\n",
      "2446/2446 [==============================] - 1082s 442ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0073 - val_accuracy: 0.9979 - lr: 1.0000e-05\n",
      "Epoch 57/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9969\n",
      "Epoch 57: val_loss did not improve from 0.00723\n",
      "2446/2446 [==============================] - 1094s 447ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0073 - val_accuracy: 0.9979 - lr: 1.0000e-05\n",
      "Epoch 58/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9969\n",
      "Epoch 58: val_loss did not improve from 0.00723\n",
      "2446/2446 [==============================] - 1102s 450ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0073 - val_accuracy: 0.9979 - lr: 1.0000e-05\n",
      "Epoch 59/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9969\n",
      "Epoch 59: val_loss improved from 0.00723 to 0.00723, saving model to ./checkpoint\\model_weights.h5\n",
      "2446/2446 [==============================] - 1102s 451ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0072 - val_accuracy: 0.9979 - lr: 1.0000e-05\n",
      "Epoch 60/150\n",
      "2446/2446 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9969\n",
      "Epoch 60: val_loss improved from 0.00723 to 0.00722, saving model to ./checkpoint\\model_weights.h5\n",
      "2446/2446 [==============================] - 1106s 452ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0072 - val_accuracy: 0.9979 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train,\n",
    "                    validation_data = (X_test, y_test), \n",
    "                    epochs = 15, batch_size = 512, \n",
    "                    callbacks = [checkpoint, reduce_lr])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
